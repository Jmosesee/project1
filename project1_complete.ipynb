{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from urllib.parse import parse_qs\n",
    "import glob\n",
    "import matplotlib.pylab as plt\n",
    "from collections import Counter\n",
    "import collections\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/CSR/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_links_page(page):\n",
    "    base_url = \"https://www.indeed.com/jobs?\"\n",
    "    params = {'q': 'data scientist', \n",
    "             'l': 'Boulder, CO'}\n",
    "    \n",
    "\n",
    "    # start = \"https://www.indeed.com/jobs?q=Data+Scientist&l=Denver%2C+CO\"\n",
    "    # use a fake header\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'}\n",
    "    params['start'] = 20 * (page-1)\n",
    "\n",
    "    page = requests.get(base_url, params=params, headers=headers)\n",
    "    # test = requests.get(start, headers=headers)\n",
    "    \n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    \n",
    "    # build a list of links\n",
    "    some_links = []\n",
    "\n",
    "    for l in links:\n",
    "        try:\n",
    "            hyperlink = l.attrs.get('href')\n",
    "            if \"/rc/clk?\" in hyperlink:\n",
    "                some_links.append(l.attrs.get('href'))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    job_links = [\"https://www.indeed.com{}\".format(x)\n",
    "             for x in some_links\n",
    "             ]\n",
    "    \n",
    "    return job_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [get_job_links_page(x) for x in range(1, 40)] # getting a link for 39 pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/rc/clk?jk=c9d84c941c6b6d2f&fccid=4600afcfb0f58ad6&vjs=3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = list(itertools.chain(*links))\n",
    "len(merged)\n",
    "merged[0] # getting a link for 39 pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_url(some_url):\n",
    "    parsed = parse_qs(some_url)\n",
    "    fccid =  parsed.get('fccid')[0]\n",
    "    other_id = parsed.get('https://www.indeed.com/rc/clk?jk')[0]\n",
    "    return fccid+other_id+ \".html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filename_from_url(merged[0]) # file name for each html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([get_filename_from_url(x) for x in merged])) # the total number of html files(jobs) parsed and saved locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading each html file as a soup object\n",
    "def download_job_page(link):\n",
    "    save_name = get_filename_from_url(link)\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'}\n",
    "    test = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(test.text, \"html.parser\")\n",
    "    \n",
    "    with open('data_scienceBoulder_{}'.format(save_name), 'w') as f:\n",
    "        f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in tqdm(merged):\n",
    "    try:\n",
    "        download_job_page(link)\n",
    "    except Exception as e:\n",
    "        print(str(e), link)\n",
    "    finally:\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1775"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = glob.glob('*.html')\n",
    "len(html) # the total number of html files(jobs) parsed and saved locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n",
      "The job summary field does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1763"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_divs = []\n",
    "\n",
    "for html_file in html:\n",
    "    with open(html_file, 'r',encoding=\"ISO-8859-1\") as f:\n",
    "        _data = BeautifulSoup(f.read(), \"html.parser\")\n",
    "        try:\n",
    "            has_span_job_summary = _data.find(\"span\", id=\"job_summary\").get_text()\n",
    "            html_divs.append(has_span_job_summary)\n",
    "        except:\n",
    "            print('The job summary field does not exist.')\n",
    "        \n",
    "len(html_divs) # total numbers of job postings saved locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Come join a fast-paced technology organization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summary\\nThe Business Intelligence Analyst is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Administrator\\nFlexential stands for some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Institutional Planning &amp; Analysis departme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location(s): CO - Denver; MN - Minneapolis\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perform business architecture, Human Resources...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Working as a member of Blue Moon Digital, Inc....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dedicated to quality, innovation, engagement, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job Description\\n\\nRLH Revenue Team Overview:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arcadis is looking for an experienced Manageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It's exciting to work for a company that makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From our start in 2009, Conexess has establish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Company Overview\\nIntrapreneurship is defined ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Key Functions\\n\\n\\n\\nThis role responsible for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ITS Performance Reporting Analyst\\n\\nKey Funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CDM Smith is seeking a Enterprise Data Archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The team is currently senior heavy and they wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Quality Assurance Analyst\\n\\nAs a Sr. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Position: BI/Reporting Developer\\n\\nJob Descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This position requires a diverse background to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_summary\n",
       "0   Come join a fast-paced technology organization...\n",
       "1   Summary\\nThe Business Intelligence Analyst is ...\n",
       "2   Data Administrator\\nFlexential stands for some...\n",
       "3   The Institutional Planning & Analysis departme...\n",
       "4   Location(s): CO - Denver; MN - Minneapolis\\n\\n...\n",
       "5   Perform business architecture, Human Resources...\n",
       "6   Working as a member of Blue Moon Digital, Inc....\n",
       "7   Dedicated to quality, innovation, engagement, ...\n",
       "8   Job Description\\n\\nRLH Revenue Team Overview:\\...\n",
       "9   Arcadis is looking for an experienced Manageme...\n",
       "10  It's exciting to work for a company that makes...\n",
       "11  From our start in 2009, Conexess has establish...\n",
       "12  Company Overview\\nIntrapreneurship is defined ...\n",
       "13  Key Functions\\n\\n\\n\\nThis role responsible for...\n",
       "14  ITS Performance Reporting Analyst\\n\\nKey Funct...\n",
       "15  CDM Smith is seeking a Enterprise Data Archite...\n",
       "16  The team is currently senior heavy and they wi...\n",
       "17  Senior Quality Assurance Analyst\\n\\nAs a Sr. S...\n",
       "18  Position: BI/Reporting Developer\\n\\nJob Descri...\n",
       "19  This position requires a diverse background to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.DataFrame(html_divs)\n",
    "jobs.columns = ['job_summary']\n",
    "jobs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photofeeler (&lt;a href=\"https:&amp;#x2F;&amp;#x2F;www.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q-Branch Labs (&lt;a href=\"https:&amp;#x2F;&amp;#x2F;www....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldwide, REMOTE, full time or part time -- 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lendable | Senior Software Engineers, Senior D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gambit Research Ltd (&lt;a href=\"http:&amp;#x2F;&amp;#x2F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_summary\n",
       "0  Photofeeler (<a href=\"https:&#x2F;&#x2F;www.ph...\n",
       "1  Q-Branch Labs (<a href=\"https:&#x2F;&#x2F;www....\n",
       "2  Worldwide, REMOTE, full time or part time -- 1...\n",
       "3  Lendable | Senior Software Engineers, Senior D...\n",
       "4  Gambit Research Ltd (<a href=\"http:&#x2F;&#x2F..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('hacker_news.csv')\n",
    "del df1['source']\n",
    "df1.rename(columns={'desc': 'job_summary'}, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-594ebd078071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "all_jobs=pd.concat([df1,jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Photofeeler (<a href=\"https:&#x2F;&#x2F;www.photofeeler.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.photofeeler.com</a>) | Software Engineers, Marketing Roles | REMOTE or Onsite near Boulder, CO<p>If you were a fan of the old OkCupid blog or Christian Rudder&#x27;s &quot;Dataclysm,&quot; you will love it here.<p>Photofeeler is a tool for photo feedback, but we&#x27;re primarily a data science company. We do math to maximize the statistical value of small, noisy data samples. Our company is changing the future of online profiles.<p>The gig offers unparalleled freedom without beauracratic nonsense (think: can work remote, work flexible hours, no unnecessary meetings). Our users are eager and enthusiastic for everything that we build.<p>More info: <a href=\"https:&#x2F;&#x2F;www.photofeeler.com&#x2F;jobs\" rel=\"nofollow\">https:&#x2F;&#x2F;www.photofeeler.com&#x2F;jobs</a>',\n",
       "       'Q-Branch Labs (<a href=\"https:&#x2F;&#x2F;www.q-branch.net\" rel=\"nofollow\">https:&#x2F;&#x2F;www.q-branch.net</a>) | Marketing Director, Hardware Product Manager, Python Developer | FULL-TIME | London | ONSITE | £50-75K + equity<p>Join a team helping to protect smart homes from the internet of insecure things.  We all know IoT and connected-devices are a security nightmare:  infrequently updated, often insecure by design, and a constantly growing source of zombie devices for botnet herders.  Help a seed-funded startup solve this problem for the huge mass of people who are not security&#x2F;networking experts and need an easy to install and easy to use solution!<p>Marketing Director - Q-Branch is looking for an ambitious marketing director who has experience in crafting a startup marketing plan from the ground up; messaging, PR, advertising and design.  Crowdfunding and social media management experience strongly desired.<p>Hardware Product Manager - We need someone with experience in delivering a consumer hardware product, from CAD design and injection molding to assembly and shipping.  We need someone with experience in sourcing parts, performing hardware QA and certification, and handling the end-to-end pipeline from development to delivery.<p>Python Developer - Q-Branch is also looking for an experienced Python developer with a strong linux&#x2F;unix background. Role will involve devops work (Ansible&#x2F;Kubernetes&#x2F;Terraform on AWS) as well as work on a large-scale event processing pipeline feeding a variety of analytics engines. Some experience in cyber-security, security data analytics, and machine learning are all major wins for a candidate.<p>Contact us at jobs@q-branch.net for more info or check us out on AngelList (<a href=\"https:&#x2F;&#x2F;angel.co&#x2F;q-branch-labs&#x2F;jobs\" rel=\"nofollow\">https:&#x2F;&#x2F;angel.co&#x2F;q-branch-labs&#x2F;jobs</a>)',\n",
       "       'Worldwide, REMOTE, full time or part time -- 100% flexibility. $70-100&#x2F;hr. Expert Interviewer at Karat (<a href=\"https:&#x2F;&#x2F;karat.io\" rel=\"nofollow\">https:&#x2F;&#x2F;karat.io</a>)<p>Work from anywhere in the world that has a solid internet connection. Work as much or as little as you want. Work any day, any time of day, any number of hours -- you can do 0 one week, 50 the next week, and back to 0 the next week. Only requirement there is that we want you to roughly average at least 10 hours a week, or else the training&#x2F;time investment doesn&#x27;t make as much sense from your end or ours.<p>I know the above might sound a little strange, so a bit about the company for context: Karat is a Seattle-based startup that does software engineering interviews on behalf of other companies -- primarily first-round phone screens. Quickly-growing companies can spend a significant fraction of their engineers&#x27; time interviewing; we help take the load off. We&#x27;ve done a lot to make the interview experience better for all stakeholders that I could write whole essays about, but suffice it to say that candidates love working with us, clients love working with us, and we&#x27;re well-funded and growing quickly as a result.<p>Because of this quickly-growing demand, we&#x27;re looking to hire more Expert Interviewers. The ideal candidate is a software engineer with strong written and verbal English skills with at least a few years of professional experience. Interviewing experience would be great, but we spend 25 hours (paid) training you before you even start, so if you&#x27;re strong technically and love working with people we can usually make it work :) Interviews are conducted over video chat, using a collaborative code editor.<p>Some of our interviewers are freelancers who use our scheduling model to backfill hours; others are full timers at top tech companies looking to make some extra cash; others have quit their jobs to work with us full time; some are digital nomads; one of our interviewers is road tripping around North America for a year and a half, doing anywhere from zero to 40 interviews each week depending on where he is and what the weather&#x27;s like.<p>The application form is here: <a href=\"https:&#x2F;&#x2F;jobs.lever.co&#x2F;karat&#x2F;d44ab283-c7c0-4bbd-b8c3-4dc0ced64c86?lever-origin=applied&amp;lever-source=HNWH\" rel=\"nofollow\">https:&#x2F;&#x2F;jobs.lever.co&#x2F;karat&#x2F;d44ab283-c7c0-4bbd-b8c3-4dc0ced6...</a><p>I know it&#x27;s a pretty unique job, so if you have any questions reply here or email me at josh@karat.io and I&#x27;m happy to talk through any of it.<p>P.S. We&#x27;re also hiring for our internal team -- particularly looking for senior engineers right now; for those we generally prefer local (Seattle) candidates, though we do cover relocation. More details on those here: <a href=\"https:&#x2F;&#x2F;karat.io&#x2F;careers\" rel=\"nofollow\">https:&#x2F;&#x2F;karat.io&#x2F;careers</a>, or feel free to email me if you have any questions.',\n",
       "       ...,\n",
       "       'Company Overview\\nCosmic Advanced Engineered Solutions (Cosmic AES) is a small innovative company tackling the most difficult technical challenges in signals, space, and cyberspace. We design and develop high-end signal processing solutions for Department of Defense(DoD) in the Counter-Space, Special Operations, Homeland Security, and other specialized mission areas. Our strong team of scientists, engineers, and operations experts specialize in exploring emerging technologies, system development, and rapid prototyping to solve the most difficult national security concerns.\\nJob Summary\\nCosmic AES is looking for a software engineer to support the Air Force Space and Missile Systems Center (SMC), Remote Sensing Directorate (RS). The candidate will support data exploitation of Wide Field of View (WFOV) data. Additionally, the candidate will work directly with operators within the Overhead Persistent Infrared Battlespace Awareness Center (OBAC) at Buckley AFB, CO to provide enhancements to imagery tools.\\nResponsibilities and Duties\\n2+ years of software development experience with Groovy/JAVA\\nLead in the implementation of microservices.\\nDevelop additional REST endpoints in existing microservices as well as developing new microservices. Microservices will be implemented in Groovy/Java using the Grails web framework, and other JVM-based languages and technologies.\\nAlgorithm development.\\nApplication deployment and load-balancing.\\nPersistence tuning and optimization including use of Hibernate and JPA.\\nQualifications and Skills\\nUS citizen, and must be able to obtain and maintain Top Secret security clearance\\nEducation and/or background in software development and software engineering\\nProficiency developing in Java or Groovy\\nTeam player and capable of working in a fast-pasted, team environment\\nDesired Qualifications\\nProficiency developing with Grails or similar convention-over-configuration stack\\nExperience with Agile methodologies\\nBenefits and Perks\\nCompetitive salary\\nGreat benefits package including Medical, Dental, Vision, and more! (Cosmic contributes 85% of the medical plan cost for employees and 75% for dependent coverage)\\n401K and Profit Sharing\\nVacation (benefits based on professional experience, not time with the company)\\nWork/Life balance\\nEmployee Referral Incentives\\n7 paid holidays and 3 floating holidays',\n",
       "       'Make an impact and love what you do! Headquartered in the heart of downtown Denver, Vertafore is a top provider of software for the insurance industry that keeps transforming. We create award-winning solutions to boost productivity, lower costs and help agents and carriers grow their businesses. We respect and value our team, and we look to bring the best talent together to make our future even stronger.\\n\\nThis role will assist with the launch and support of multiple technical products. You\\x92ll act as the voice of the customer to continue to transform our marketing messages in ways that help our customers adapt to a quickly changing technology market.\\n\\nYou\\x92ll work closely with various internal teams and work closely with your internal marketing partners. You\\x92ll assist with the definition of the product positioning, market plans, and sales enablement plans. You\\x92ll help define the role that digital marketing plays in product awareness, trial and demand generation. You\\x92ll help test and optimize new ways to engage customers. And you\\x92ll use insights and analytics to make decisions on where to invest and how to evolve programs.\\n\\nVertafore is about bringing together top talent to make an immediate impact in software. Our culture encourages employees who are able to create, think and challenge each other in a fast-paced environment. We are transforming our products and services, exploiting advanced techniques to create new \\x93ways and means\\x94 for the insurance industry, and with that the industry is changing too.\\n\\nVertafore strongly supports equal employment opportunity for all applicants regardless of race, color, religion, sex, gender identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, sexual orientation, genetic information, or any other characteristic protected by state or federal law equal employment.\\n\\n\\n1-2 years of experience in a relevant B2B or B2C digital or product marketing discipline.\\nDemonstrated success launching new products to market and partnering with a sales organization.\\nStrong communication with talent to simplify complex messages to easy to understand stories.\\nExperience with A/B testing data measurement and analytics tools.\\nDetailed oriented and sets high threshold for quality.\\nSelf-motivated with drive and determination to succeed.\\nA team player \\x96 prepared to do what it takes to meet the goals of the team.\\nExperience managing marketing agencies and outside partners.\\n\\n',\n",
       "       'Summary:\\n\\nThis individual will serve as a team member on multiple drug discovery project teams and Arrayâ\\x80\\x99s New Targets Initiative. Accordingly, the candidate must possess extensive experience developing quantitative cell-based assays to support small molecule lead optimization. The candidate should also be experienced in executing compound mechanism of action studies to inform translational sciences efforts and guide clinical strategy. The ideal candidate will also have significant experience with target identification/validation approaches, strategies and techniques (chemical biology/shRNA/CRISPR).\\n\\nResponsibilities:\\n\\nDevelops and runs quantitative cell-based assays employing primary cells or engineered cell lines to support drug discovery project teams\\nAnalyzes, interprets and reports out data to the various teams in a timely manner with an emphasis on quality and reproducibility\\nEffectively plans and conducts both routine and exploratory experiments employing established internal and/or published procedures with a high degree of independence and precision\\nParticipates in both the design and implementation of screening and validation efforts to identify novel therapeutic targets in oncology employing a variety of chemical and molecular genetic platforms and experimental systems\\nMakes recommendations for changes in experimental strategy and procedures to improve quality or productivity\\nContributes to written and oral presentations related to work being conducted for both internal and external presentation and publication\\nTrains other laboratory personnel in experimental details pertaining to current or previous work\\nPossesses and maintains state-of-the-art technical skills and knowledge base in a scientific discipline or technology\\n\\nPhD with 3-5 years small molecule drug discovery experience or a BS/MS with at least ten yearsâ\\x80\\x99 experience\\nExtensive familiarity in the generation and maintenance of cell lines and primary cells\\nProven expertise in quantitative assay development using standard Cell Biology techniques (ELISA, LICOR, MSD)\\nHands on experience with medium throughput (96 well) phenotypic screening efforts employing small molecules and/or molecular genetic approaches (shRNA/CRISPR)\\nPossesses core cell and molecular biology skills including nucleic acid purification, DNA/RNA transfection/transduction (Lentivirus, nucleofection, Retrovirus, etc.)\\nComputer skills with MS Office (Excel, Word, PPT) and basic statistical analysis software (e.g., Prism, SigmaPlot)\\nRegularly conceives and applies innovative, technical solutions to a variety of problems\\nEffective independent researcher with a solid understanding of cell biology having both an ability and an interest in learning new biology, approaches and techniques\\nOperates with substantial latitude for independent actions and decisions relating to technical problems and procedures\\nRecognized company-wide as a subject matter and/or technical expert in certain areas\\nGood problem-solving skills'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs.job_summary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_skills_list():\n",
    "    import pandas as pd\n",
    "    skills = pd.read_csv('skill_phrases-JBM.csv', encoding=\"ISO-8859-1\")\n",
    "    skills.columns = ['skill_name']\n",
    "    skills['skill_name'] = skills.skill_name.map(lambda x: \n",
    "                                               x.lower().strip())\n",
    "    return skills.skill_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>social aptitudes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geodatabase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         skill_name\n",
       "0  social aptitudes\n",
       "1       geodatabase\n",
       "2               e2e\n",
       "3          analysts\n",
       "4              hive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv('skill_phrases-JBM.csv', encoding=\"ISO-8859-1\")\n",
    "skills.columns = ['skill_name']\n",
    "skills['skill_name'] = skills.skill_name.map(lambda x: \n",
    "                                           x.lower().strip())\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_skills = skills.skill_name.tolist() # All skills we know of\n",
    "list_of_skills = [x.replace(\"\\xa0\", \" \").replace(\"\\x92s\", \" \") for x in list_of_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2c1016a19989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#make a big string of all job descriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjob_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjob_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjob_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjob_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjob_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjob_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove english language stop words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_jobs' is not defined"
     ]
    }
   ],
   "source": [
    "#make a big string of all job descriptions\n",
    "job_string = \" \".join(all_jobs.job_summary.tolist())\n",
    "job_tokens = nltk.word_tokenize(job_string)\n",
    "job_tokens = [word for word in job_tokens if len(word) >= 1] # remove space \n",
    "job_tokens = [word for word in job_tokens if not word in stop_words] # remove english language stop words \n",
    "job_tokens = [word.lower().strip() for word in job_tokens if not word in string.punctuation]\n",
    "\n",
    "assert(type(job_tokens) == list)\n",
    "filtered = Counter([x for x in job_tokens if x in list_of_skills])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('development', 3445),\n",
       " ('software', 3245),\n",
       " ('analysis', 3145),\n",
       " ('research', 2299),\n",
       " ('design', 2008),\n",
       " ('engineering', 1983),\n",
       " ('communication', 1619),\n",
       " ('analyst', 1474),\n",
       " ('engineers', 1396),\n",
       " ('analytics', 1235)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.most_common(10) # looking across skill frequency for all jobs, one way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_skills_for_search_kw(search_term, dataframe_name, list_of_skills):\n",
    "\n",
    "    \n",
    "    matches = defaultdict(int)\n",
    "\n",
    "    for index, row in dataframe_name.iterrows():\n",
    "        job_desc = row.job_summary # local specificity \n",
    "        job_tokens = nltk.word_tokenize(job_desc)\n",
    "        job_tokens = [word for word in job_tokens if len(word) >= 1] # remove space \n",
    "        job_tokens = [word for word in job_tokens if not word in stop_words] # remove english language stop words \n",
    "        job_tokens = [word.lower().strip() for word in job_tokens if not word in string.punctuation ] \n",
    "        \n",
    "        if search_term in job_tokens:\n",
    "            for skill in list_of_skills:\n",
    "                if (skill in job_tokens) & (skill !=search_keyword):\n",
    "                    matches[skill] += 1\n",
    "                    \n",
    "    return Counter(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_keyword' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d9ba25a15985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                 \u001b[0mall_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                 list_of_skills) \n\u001b[1;32m----> 6\u001b[1;33m                for query in LIST_OF_QUERIES  }\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-d9ba25a15985>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                 \u001b[0mall_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                 list_of_skills) \n\u001b[1;32m----> 6\u001b[1;33m                for query in LIST_OF_QUERIES  }\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-cbe66d18f867>\u001b[0m in \u001b[0;36mget_matching_skills_for_search_kw\u001b[1;34m(search_term, dataframe_name, list_of_skills)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msearch_term\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjob_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mskill\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_skills\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskill\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjob_tokens\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskill\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[0msearch_keyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mmatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mskill\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'search_keyword' is not defined"
     ]
    }
   ],
   "source": [
    "LIST_OF_QUERIES = ['sql', 'python', 'javascript', 'java', 'excel'] # obviously use more\n",
    "\n",
    "all_matches =  { query: get_matching_skills_for_search_kw(query, \n",
    "                                                all_jobs, \n",
    "                                                list_of_skills) \n",
    "               for query in LIST_OF_QUERIES  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches\n",
    "# all_matches ===> {query: counter object, query: counter object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=collections.Counter(matches)\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = matches.keys()\n",
    "sizes = matches.values()\n",
    "fig1, ax1 = plt.subplots()\n",
    "fig1.set_size_inches(4,4)\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', pctdistance=0.8, labeldistance=1.3,\n",
    "        shadow=True, startangle=90)\n",
    "#plt.title('% of Skills')\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "ax1.axis('equal')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('hacker_news.csv')\n",
    "del df1['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df1['source']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_list = df1.job_summary.tolist()\n",
    "mark_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_list = [x.replace('\\<a href=\"https:&#x2F;&#x2F;www.photofeeler.com\"', \" \").replace(\"\\x92s\", \" \") for x in mark_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'desc': 'job_summary'}, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=pd.concat([df1,jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.job_summary.unique().shape)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in jobs.iterrows():\n",
    "    \n",
    "    job_desc = row.job_summary\n",
    "\n",
    "    #job_tokens = nltk.word_tokenize(job_desc)\n",
    "    \n",
    "    job_tokens = [word_tokenize(word) for word in tqdm(job_desc)]\n",
    "    \n",
    "    \n",
    "    #job_tokens = [word for word in job_tokens if len(word) >= 1] # remove space \n",
    "    \n",
    "    #job_tokens = [word for word in job_tokens if not word in stop_words] # remove english language stop words \n",
    "    \n",
    "    #job_tokens = [word.lower().strip() for word \n",
    "                  #in job_tokens if not word in string.punctuation ] # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_found = 0\n",
    "search_keyword= \"data\"\n",
    "matching_skill= search_keyword in job_tokens\n",
    "    \n",
    "if matching_skill:\n",
    "    match_found +=1\n",
    "    matches= defaultdict(int)  \n",
    "        \n",
    "    for skill in list_of_skills:\n",
    "        if (skill in job_tokens) & (skill !=search_keyword):\n",
    "            matches[skill] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
